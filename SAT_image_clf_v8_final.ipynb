{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SAT image clf v8 final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jkfVHASbq5GC"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajeymr/Satellite-Image-Classification/blob/master/SAT_image_clf_v8_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKrfxKkDbaSZ"
      },
      "source": [
        "## Installation and importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OJGAkEvQXBN",
        "outputId": "941a6b0f-d5e2-4838-8615-55857c1193d3"
      },
      "source": [
        "!pip install keras\n",
        "!pip install tensorflow\n",
        "!pip install  -U keras-tuner\n",
        "!pip install kerastuner-tensorboard-logger\n",
        "\n",
        "print(\"keras and tensorflow installed\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.15.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (56.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.28.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.10.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.8.9)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->keras-tuner) (1.0.1)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp37-none-any.whl size=78938 sha256=9b434171fa6d5ccd6cd136aedf2077cceee087e25d33ddb73fd69e5dda69d4a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp37-none-any.whl size=15356 sha256=0fd7d77530b7753d5d13d2f6034b3f3d97851ffba287ec91af8f40a61af5d17b\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0\n",
            "Collecting kerastuner-tensorboard-logger\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/8f/61a425a131b2cb9423d71066ca9ef1065f214b5473d8637f677ebdceacaa/kerastuner_tensorboard_logger-0.2.3-py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from kerastuner-tensorboard-logger) (2.4.1)\n",
            "Requirement already satisfied: keras-tuner<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from kerastuner-tensorboard-logger) (1.0.2)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (2.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (0.3.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (2.4.1)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (1.1.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (3.7.4.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (1.12)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (3.12.4)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (1.1.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (0.2.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (0.36.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (2.4.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (1.32.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (3.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner<2.0,>=1.0->kerastuner-tensorboard-logger) (1.4.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner<2.0,>=1.0->kerastuner-tensorboard-logger) (0.8.9)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner<2.0,>=1.0->kerastuner-tensorboard-logger) (20.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from keras-tuner<2.0,>=1.0->kerastuner-tensorboard-logger) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner<2.0,>=1.0->kerastuner-tensorboard-logger) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner<2.0,>=1.0->kerastuner-tensorboard-logger) (2.23.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from keras-tuner<2.0,>=1.0->kerastuner-tensorboard-logger) (0.16.0)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.7/dist-packages (from keras-tuner<2.0,>=1.0->kerastuner-tensorboard-logger) (3.1.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from keras-tuner<2.0,>=1.0->kerastuner-tensorboard-logger) (0.4.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (56.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (0.4.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (1.28.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner<2.0,>=1.0->kerastuner-tensorboard-logger) (2.4.7)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->keras-tuner<2.0,>=1.0->kerastuner-tensorboard-logger) (1.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner<2.0,>=1.0->kerastuner-tensorboard-logger) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner<2.0,>=1.0->kerastuner-tensorboard-logger) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner<2.0,>=1.0->kerastuner-tensorboard-logger) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner<2.0,>=1.0->kerastuner-tensorboard-logger) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (3.10.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (4.2.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3.0,>=2.0->kerastuner-tensorboard-logger) (0.4.8)\n",
            "Installing collected packages: kerastuner-tensorboard-logger\n",
            "Successfully installed kerastuner-tensorboard-logger-0.2.3\n",
            "keras and tensorflow installed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWpklF4IR6VR",
        "outputId": "6a683958-695c-4d1b-8fca-56508f509515"
      },
      "source": [
        "from skimage.io import imshow\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from kerastuner_tensorboard_logger import TensorBoardLogger\n",
        "from kerastuner.tuners import Hyperband\n",
        "import time\n",
        "\n",
        "print(\"Libraries Imported\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Libraries Imported\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPu5m_2gblCf"
      },
      "source": [
        "## Importing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMkf_GU1fE8Z",
        "outputId": "d951b312-fd08-4ccb-c133-9a3552d680fe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTFmKOaHewG-",
        "outputId": "68e1ba4c-20e4-4210-9b0f-0642c4bc3171"
      },
      "source": [
        "X = pd.read_csv('/content/drive/My Drive/Satellite image classification/X_train_sat4.csv', header = None)\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 3136)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoO5nwp4fLLx",
        "outputId": "932d4fc0-b2ed-41ed-e475-55d07892b573"
      },
      "source": [
        "y = pd.read_csv('/content/drive/My Drive/Satellite image classification/y_train_sat4.csv', header = None)\n",
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6ubbN5yCnXf",
        "outputId": "b1678b3c-cfb6-468d-f4e9-b4f720646523"
      },
      "source": [
        "X_test = pd.read_csv('/content/drive/My Drive/Satellite image classification/X_test_sat4.csv', header = None)\n",
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99999, 3136)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ntt-vSzMC6_7",
        "outputId": "7be1f8cd-9ef8-4487-e2a5-b2a6844cceef"
      },
      "source": [
        "y_test = pd.read_csv('/content/drive/My Drive/Satellite image classification/y_test_sat4.csv', header = None)\n",
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3YO1sW4tJLu"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(np.array(X).astype('float32').reshape(400000,28,28,4)/255, np.array(y).astype('int32'), test_size = 0.2, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc0ECxdeuhwl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d15f0f0-bad8-4a28-8c2a-087ae53c055f"
      },
      "source": [
        "print('X_train shape : ', X_train.shape)\n",
        "print('X_test shape : ', X_test.shape)\n",
        "print('y_train shape : ', y_train.shape)\n",
        "print('y_test shape : ', y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape :  (320000, 28, 28, 4)\n",
            "X_test shape :  (80000, 28, 28, 4)\n",
            "y_train shape :  (320000, 4)\n",
            "y_test shape :  (80000, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgTc-MekcDgm"
      },
      "source": [
        "## Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "jxzSTIioQI80",
        "outputId": "7248f1b9-b41c-4ddb-8ff7-3e39af1f234d"
      },
      "source": [
        "pd.DataFrame(X_train.reshape(320000,3136)).head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>3096</th>\n",
              "      <th>3097</th>\n",
              "      <th>3098</th>\n",
              "      <th>3099</th>\n",
              "      <th>3100</th>\n",
              "      <th>3101</th>\n",
              "      <th>3102</th>\n",
              "      <th>3103</th>\n",
              "      <th>3104</th>\n",
              "      <th>3105</th>\n",
              "      <th>3106</th>\n",
              "      <th>3107</th>\n",
              "      <th>3108</th>\n",
              "      <th>3109</th>\n",
              "      <th>3110</th>\n",
              "      <th>3111</th>\n",
              "      <th>3112</th>\n",
              "      <th>3113</th>\n",
              "      <th>3114</th>\n",
              "      <th>3115</th>\n",
              "      <th>3116</th>\n",
              "      <th>3117</th>\n",
              "      <th>3118</th>\n",
              "      <th>3119</th>\n",
              "      <th>3120</th>\n",
              "      <th>3121</th>\n",
              "      <th>3122</th>\n",
              "      <th>3123</th>\n",
              "      <th>3124</th>\n",
              "      <th>3125</th>\n",
              "      <th>3126</th>\n",
              "      <th>3127</th>\n",
              "      <th>3128</th>\n",
              "      <th>3129</th>\n",
              "      <th>3130</th>\n",
              "      <th>3131</th>\n",
              "      <th>3132</th>\n",
              "      <th>3133</th>\n",
              "      <th>3134</th>\n",
              "      <th>3135</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.564706</td>\n",
              "      <td>0.568627</td>\n",
              "      <td>0.505882</td>\n",
              "      <td>0.737255</td>\n",
              "      <td>0.541176</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.729412</td>\n",
              "      <td>0.521569</td>\n",
              "      <td>0.498039</td>\n",
              "      <td>0.435294</td>\n",
              "      <td>0.709804</td>\n",
              "      <td>0.552941</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.478431</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.552941</td>\n",
              "      <td>0.541176</td>\n",
              "      <td>0.490196</td>\n",
              "      <td>0.749020</td>\n",
              "      <td>0.447059</td>\n",
              "      <td>0.407843</td>\n",
              "      <td>0.345098</td>\n",
              "      <td>0.639216</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.592157</td>\n",
              "      <td>0.564706</td>\n",
              "      <td>0.780392</td>\n",
              "      <td>0.368627</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.509804</td>\n",
              "      <td>0.372549</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.274510</td>\n",
              "      <td>0.494118</td>\n",
              "      <td>0.525490</td>\n",
              "      <td>0.517647</td>\n",
              "      <td>0.482353</td>\n",
              "      <td>0.713726</td>\n",
              "      <td>...</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>0.270588</td>\n",
              "      <td>0.227451</td>\n",
              "      <td>0.321569</td>\n",
              "      <td>0.384314</td>\n",
              "      <td>0.392157</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.486275</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.270588</td>\n",
              "      <td>0.250980</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.415686</td>\n",
              "      <td>0.462745</td>\n",
              "      <td>0.521569</td>\n",
              "      <td>0.419608</td>\n",
              "      <td>0.462745</td>\n",
              "      <td>0.525490</td>\n",
              "      <td>0.572549</td>\n",
              "      <td>0.376471</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.407843</td>\n",
              "      <td>0.498039</td>\n",
              "      <td>0.396078</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.450980</td>\n",
              "      <td>0.521569</td>\n",
              "      <td>0.301961</td>\n",
              "      <td>0.286275</td>\n",
              "      <td>0.274510</td>\n",
              "      <td>0.341176</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.274510</td>\n",
              "      <td>0.258824</td>\n",
              "      <td>0.329412</td>\n",
              "      <td>0.317647</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.282353</td>\n",
              "      <td>0.345098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.537255</td>\n",
              "      <td>0.498039</td>\n",
              "      <td>0.635294</td>\n",
              "      <td>0.584314</td>\n",
              "      <td>0.537255</td>\n",
              "      <td>0.494118</td>\n",
              "      <td>0.635294</td>\n",
              "      <td>0.576471</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.482353</td>\n",
              "      <td>0.635294</td>\n",
              "      <td>0.568627</td>\n",
              "      <td>0.525490</td>\n",
              "      <td>0.482353</td>\n",
              "      <td>0.643137</td>\n",
              "      <td>0.580392</td>\n",
              "      <td>0.537255</td>\n",
              "      <td>0.494118</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.580392</td>\n",
              "      <td>0.537255</td>\n",
              "      <td>0.509804</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.572549</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.494118</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.580392</td>\n",
              "      <td>0.537255</td>\n",
              "      <td>0.498039</td>\n",
              "      <td>0.654902</td>\n",
              "      <td>0.564706</td>\n",
              "      <td>0.521569</td>\n",
              "      <td>0.486275</td>\n",
              "      <td>0.658824</td>\n",
              "      <td>0.549020</td>\n",
              "      <td>0.505882</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.654902</td>\n",
              "      <td>...</td>\n",
              "      <td>0.537255</td>\n",
              "      <td>0.490196</td>\n",
              "      <td>0.443137</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.545098</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.447059</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.560784</td>\n",
              "      <td>0.517647</td>\n",
              "      <td>0.458824</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.568627</td>\n",
              "      <td>0.521569</td>\n",
              "      <td>0.482353</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.572549</td>\n",
              "      <td>0.521569</td>\n",
              "      <td>0.494118</td>\n",
              "      <td>0.611765</td>\n",
              "      <td>0.580392</td>\n",
              "      <td>0.529412</td>\n",
              "      <td>0.498039</td>\n",
              "      <td>0.607843</td>\n",
              "      <td>0.560784</td>\n",
              "      <td>0.509804</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.596078</td>\n",
              "      <td>0.576471</td>\n",
              "      <td>0.521569</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.592157</td>\n",
              "      <td>0.556863</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.458824</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.564706</td>\n",
              "      <td>0.513726</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.596078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.407843</td>\n",
              "      <td>0.427451</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.537255</td>\n",
              "      <td>0.392157</td>\n",
              "      <td>0.439216</td>\n",
              "      <td>0.392157</td>\n",
              "      <td>0.521569</td>\n",
              "      <td>0.305882</td>\n",
              "      <td>0.341176</td>\n",
              "      <td>0.341176</td>\n",
              "      <td>0.482353</td>\n",
              "      <td>0.364706</td>\n",
              "      <td>0.368627</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.341176</td>\n",
              "      <td>0.368627</td>\n",
              "      <td>0.415686</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.341176</td>\n",
              "      <td>0.380392</td>\n",
              "      <td>0.423529</td>\n",
              "      <td>0.345098</td>\n",
              "      <td>0.329412</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.447059</td>\n",
              "      <td>0.309804</td>\n",
              "      <td>0.376471</td>\n",
              "      <td>0.368627</td>\n",
              "      <td>0.564706</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.372549</td>\n",
              "      <td>0.368627</td>\n",
              "      <td>0.572549</td>\n",
              "      <td>0.435294</td>\n",
              "      <td>0.439216</td>\n",
              "      <td>0.431373</td>\n",
              "      <td>0.611765</td>\n",
              "      <td>...</td>\n",
              "      <td>0.341176</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.341176</td>\n",
              "      <td>0.529412</td>\n",
              "      <td>0.392157</td>\n",
              "      <td>0.368627</td>\n",
              "      <td>0.321569</td>\n",
              "      <td>0.513726</td>\n",
              "      <td>0.501961</td>\n",
              "      <td>0.462745</td>\n",
              "      <td>0.450980</td>\n",
              "      <td>0.576471</td>\n",
              "      <td>0.427451</td>\n",
              "      <td>0.341176</td>\n",
              "      <td>0.309804</td>\n",
              "      <td>0.607843</td>\n",
              "      <td>0.458824</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.364706</td>\n",
              "      <td>0.678431</td>\n",
              "      <td>0.494118</td>\n",
              "      <td>0.486275</td>\n",
              "      <td>0.447059</td>\n",
              "      <td>0.756863</td>\n",
              "      <td>0.419608</td>\n",
              "      <td>0.415686</td>\n",
              "      <td>0.384314</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.384314</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.372549</td>\n",
              "      <td>0.525490</td>\n",
              "      <td>0.384314</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.349020</td>\n",
              "      <td>0.415686</td>\n",
              "      <td>0.423529</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.380392</td>\n",
              "      <td>0.447059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.286275</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>0.258824</td>\n",
              "      <td>0.564706</td>\n",
              "      <td>0.301961</td>\n",
              "      <td>0.313726</td>\n",
              "      <td>0.282353</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>0.227451</td>\n",
              "      <td>0.549020</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>0.301961</td>\n",
              "      <td>0.262745</td>\n",
              "      <td>0.564706</td>\n",
              "      <td>0.298039</td>\n",
              "      <td>0.313726</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>0.564706</td>\n",
              "      <td>0.325490</td>\n",
              "      <td>0.349020</td>\n",
              "      <td>0.349020</td>\n",
              "      <td>0.592157</td>\n",
              "      <td>0.313726</td>\n",
              "      <td>0.341176</td>\n",
              "      <td>0.321569</td>\n",
              "      <td>0.596078</td>\n",
              "      <td>0.243137</td>\n",
              "      <td>0.258824</td>\n",
              "      <td>0.223529</td>\n",
              "      <td>0.572549</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.270588</td>\n",
              "      <td>0.250980</td>\n",
              "      <td>0.639216</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.270588</td>\n",
              "      <td>0.231373</td>\n",
              "      <td>0.654902</td>\n",
              "      <td>...</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.223529</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.603922</td>\n",
              "      <td>0.211765</td>\n",
              "      <td>0.247059</td>\n",
              "      <td>0.223529</td>\n",
              "      <td>0.631373</td>\n",
              "      <td>0.250980</td>\n",
              "      <td>0.282353</td>\n",
              "      <td>0.243137</td>\n",
              "      <td>0.670588</td>\n",
              "      <td>0.254902</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>0.258824</td>\n",
              "      <td>0.682353</td>\n",
              "      <td>0.254902</td>\n",
              "      <td>0.290196</td>\n",
              "      <td>0.270588</td>\n",
              "      <td>0.682353</td>\n",
              "      <td>0.184314</td>\n",
              "      <td>0.192157</td>\n",
              "      <td>0.149020</td>\n",
              "      <td>0.619608</td>\n",
              "      <td>0.231373</td>\n",
              "      <td>0.262745</td>\n",
              "      <td>0.243137</td>\n",
              "      <td>0.658824</td>\n",
              "      <td>0.184314</td>\n",
              "      <td>0.172549</td>\n",
              "      <td>0.156863</td>\n",
              "      <td>0.607843</td>\n",
              "      <td>0.239216</td>\n",
              "      <td>0.262745</td>\n",
              "      <td>0.231373</td>\n",
              "      <td>0.662745</td>\n",
              "      <td>0.227451</td>\n",
              "      <td>0.254902</td>\n",
              "      <td>0.215686</td>\n",
              "      <td>0.654902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.282353</td>\n",
              "      <td>0.250980</td>\n",
              "      <td>0.156863</td>\n",
              "      <td>0.513726</td>\n",
              "      <td>0.372549</td>\n",
              "      <td>0.364706</td>\n",
              "      <td>0.337255</td>\n",
              "      <td>0.603922</td>\n",
              "      <td>0.364706</td>\n",
              "      <td>0.380392</td>\n",
              "      <td>0.341176</td>\n",
              "      <td>0.615686</td>\n",
              "      <td>0.364706</td>\n",
              "      <td>0.384314</td>\n",
              "      <td>0.349020</td>\n",
              "      <td>0.607843</td>\n",
              "      <td>0.305882</td>\n",
              "      <td>0.274510</td>\n",
              "      <td>0.203922</td>\n",
              "      <td>0.490196</td>\n",
              "      <td>0.207843</td>\n",
              "      <td>0.137255</td>\n",
              "      <td>0.047059</td>\n",
              "      <td>0.384314</td>\n",
              "      <td>0.196078</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.047059</td>\n",
              "      <td>0.403922</td>\n",
              "      <td>0.282353</td>\n",
              "      <td>0.247059</td>\n",
              "      <td>0.105882</td>\n",
              "      <td>0.513726</td>\n",
              "      <td>0.396078</td>\n",
              "      <td>0.435294</td>\n",
              "      <td>0.360784</td>\n",
              "      <td>0.701961</td>\n",
              "      <td>0.450980</td>\n",
              "      <td>0.513726</td>\n",
              "      <td>0.450980</td>\n",
              "      <td>0.768627</td>\n",
              "      <td>...</td>\n",
              "      <td>0.152941</td>\n",
              "      <td>0.086275</td>\n",
              "      <td>0.094118</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.207843</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.356863</td>\n",
              "      <td>0.356863</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.580392</td>\n",
              "      <td>0.321569</td>\n",
              "      <td>0.349020</td>\n",
              "      <td>0.321569</td>\n",
              "      <td>0.552941</td>\n",
              "      <td>0.321569</td>\n",
              "      <td>0.329412</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.568627</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.435294</td>\n",
              "      <td>0.407843</td>\n",
              "      <td>0.674510</td>\n",
              "      <td>0.368627</td>\n",
              "      <td>0.407843</td>\n",
              "      <td>0.349020</td>\n",
              "      <td>0.662745</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.423529</td>\n",
              "      <td>0.372549</td>\n",
              "      <td>0.698039</td>\n",
              "      <td>0.388235</td>\n",
              "      <td>0.415686</td>\n",
              "      <td>0.364706</td>\n",
              "      <td>0.690196</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.513726</td>\n",
              "      <td>0.474510</td>\n",
              "      <td>0.756863</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3136 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0         1         2     ...      3133      3134      3135\n",
              "0  0.564706  0.568627  0.505882  ...  0.294118  0.282353  0.345098\n",
              "1  0.588235  0.537255  0.498039  ...  0.513726  0.470588  0.596078\n",
              "2  0.407843  0.427451  0.388235  ...  0.411765  0.380392  0.447059\n",
              "3  0.286275  0.290196  0.258824  ...  0.254902  0.215686  0.654902\n",
              "4  0.282353  0.250980  0.156863  ...  0.513726  0.474510  0.756863\n",
              "\n",
              "[5 rows x 3136 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "w6UAeOIecHmq",
        "outputId": "421f2ea0-ca4a-4931-8609-9729d227df05"
      },
      "source": [
        "ix = 67 # Row number\n",
        "plt.imshow(np.squeeze(X_train[ix,:,:,:])) # Only show the RGB channels\n",
        "if y_train[ix,0] == 1:\n",
        "    print ('Barren Land')\n",
        "elif y_train[ix,1] == 1:\n",
        "    print ('Trees')\n",
        "elif y_train[ix,2] == 1:\n",
        "    print ('Grassland')\n",
        "else:\n",
        "    print ('Other')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trees\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYXUlEQVR4nO2dXWykV3nH/887X/bY3l3bu+vsR2ADRLRRpYZ2FVUCValQUchN4AaRC5RKqMsFqCBRqShUIpdRVUBcVEhLiQgVBSEBIhdRS5oiRdygGBTySck23SW72W/b648Zz8z7vk8vPEEm+PyP8dgzFuf/kyzb88x53+Mz8593PP/zPI+5O4QQf/hko56AEGI4SOxCJILELkQiSOxCJILELkQiVId5sqmpSZ+dnQnGswqfDvMNDMZPHnEdKhX+updZOG4WOXeMQcczBnRbygHHs79sr50gNvfYkpdFSeOeVfgBih6Pk2dz7PlUluG5XXrjcqfb7Y1tFRtI7GZ2H4CvAKgA+Fd3f5Tdf3Z2Bv/4+b8Pxpszs/R8RRFeoMzqdKznfPFnpyZovNHYcv0AAPV6OLZB5JmV7fyFBuCiKYqCjo096TudLr+Dc1GwJ25sbmXk2PzlH+h2w495NaLV1ZU1Gs8npvkBlq/QsJfhda3VuCzXO+1g7O8+83Bw4jt+G29mFQD/AuCDAO4C8KCZ3bXT4wkh9pZB/me/B8A5d3/N3bsAvgPggd2ZlhBitxlE7CcAvL7p94v9234LMztjZvNmNr+ysjrA6YQQg7Dnn8a7+1l3P+3up6emJvf6dEKIAIOI/RKA2zf9frJ/mxBiHzKI2J8FcKeZ3WFmdQAfBfDE7kxLCLHb7Nh6c/fczD4F4D+xYb095u4vxcYxp6fb5nbHxMGjwVjEFgUivujxEydpfHHhZuQEYWIWUiX6mrtzPzqL2HpOPFsAqFb4usXWnR3fo9YZt/3cuXW3uB6eu+X886Oj0/xfzrU1/nzoxCxJ8phb5DGrVmvBmAPBEw/ks7v7kwCeHOQYQojhoO2yQiSCxC5EIkjsQiSCxC5EIkjsQiSCxC5EIgw1n91gqGRhjxA9noba67aCsbH6OB1bVnku56vnfkXjx+bmgjGPeKpecj/ZLTI+lodKDh/LGY9l0sfSLSvOrxc5SWPNImM76+uReIfGqxZ+TuS1Jh3bWuU+/For/FwE4us6ORme2/p6OIUVAHrkMa2QohC6sguRCBK7EIkgsQuRCBK7EIkgsQuRCBK7EIkwVOstywzNsbD1xqpmAsBYIzy2tXyDjm1OHKLx6sRBGl9ZXg7GpqYO0LHxStERay6ShsoquGYZP3nMmovGY3Nj5ZzpSKBW5deiygS3W1dvLARjjem30bELV9+g8aw5RePe5enat0j12swiZc+b4UrI1Xpd1psQqSOxC5EIErsQiSCxC5EIErsQiSCxC5EIErsQiTBUnx0AN50jhjQruVwnXVYBoN0K++QAMDHBl2KpHU5p7EVSczsl/7umJ3gH2Xoj0qGWONatVqQLa8SHPzDJU0F7PV7OmXXCznM+tihyGm9FUkFRD5eDbi1coEMnmtzD74zzx6xT8HVnJbrH547TsauXXw/GcrKourILkQgSuxCJILELkQgSuxCJILELkQgSuxCJILELkQhD9dnLskSblAeu1LifvLqyGIw1p3g+ehnxdHvr3IefOvqOYKx14xIdW4nkhK+1V2h8YvIIjbPM8KWcP8T1A7fR+MLCeRqfnuZ53T3SdtmMX2uaE7xtcnud+/C1PLyu0wf5/oFry9zDr0b2F2Tgra5P3hZe99evXKFjJxuNYKxLikIMJHYzOw9gBUABIHf304McTwixd+zGlf2v3J2XiRFCjBz9zy5EIgwqdgfwIzP7mZmd2eoOZnbGzObNbH4l0lJHCLF3DPo2/n3ufsnMjgJ4ysx+6e7PbL6Du58FcBYA7jj1Nv5JlRBizxjoyu7ul/rfrwH4AYB7dmNSQojdZ8diN7MJM5t682cAHwDw4m5NTAixuwzyNn4OwA/6NcurAP7d3f+Djsgy2Hg4T7ho8f/pqyQ/ubvGx+Yl92TzLm//OzsV9pPLfJaObd/gNcgt8pp7/eZ1Gu+uh71sJ2sGAJV8icZRD7eqBoDxcf6fWZGH68oXOV/z2P98Y2P86VuSPQZtsmYAUIvsAfA235fRPHwHjb9xJZyTXo+0yZ6engnG8jy8qDsWu7u/BuBPdzpeCDFcZL0JkQgSuxCJILELkQgSuxCJILELkQhDTXH1skC+FrYsYimujWa4NXK+eouOtR633rIs3A4aAFau/ToYW1/m5549xNNvby6GU3cBAA2ejpk7sZE6vHXw4hVuvU0eOkXjL7/Gx9fHw+m5eYuPzeqRtOVIW+S3nwrbX//3OrdDbzvES0W3W+HS4gDQWr1J40dmwnZtLWK9lUXYzjTSv1tXdiESQWIXIhEkdiESQWIXIhEkdiESQWIXIhEkdiESYag+e7VSw+Hpw8H4csS7LNvhlMiJMe5F1w9wz3ZlhafIthfCaaZzc7wcc3uNl4ruRNJrxw7yPQAl6YtsYUsWAOA5bzfdrHAvOzv+bhrvLYZTOU+d4KnBS8v8MSlq4ZLKANAlrbRnZw7RsfUql0Yz0tL5iPFS0t1uuKR6UfA22lUyN/dwZrCu7EIkgsQuRCJI7EIkgsQuRCJI7EIkgsQuRCJI7EIkwlB99qLIsbAYzmGeIuWaAeDoEeLRL/HSvp0W95OnIj58ox72dGM++c0lnrddclsV7UhLZza+NsHzso20ewaAbifsBwNAd+UFGm+OjwVjvR7fP8DGboce8dmjV7lIHevYupXGD5BVwj78zRXeDvpgMxxXPrsQQmIXIhUkdiESQWIXIhEkdiESQWIXIhEkdiESYbh14x0oynCC9Xqbe7o3boZrcS+v88Ttyjj3m6cifnKr1Q7GDkT2BzQavB7+rRb30WvOj58TS7dsh+cNAHnEw69NHaPx6dlwLX+A1zjPSTtngOdtA4A797Kr1fDeiLAbvUGWRXx08jwGADiPu4ePXwFvJ93tho+dVbLgokWv7Gb2mJldM7MXN902Y2ZPmdmr/e/TseMIIUbLdt7GfwPAfW+57XMAnnb3OwE83f9dCLGPie8adH8GwMJbbn4AwOP9nx8H8KFdnpcQYpfZ6Qd0c+5+uf/zFQBzoTua2Rkzmzez+ZVVXlNMCLF3DPxpvG98ShL8pMTdz7r7aXc/PTU5OejphBA7ZKdiv2pmxwCg//3a7k1JCLEX7FTsTwB4qP/zQwB+uDvTEULsFVGf3cy+DeBeAIfN7CKALwB4FMB3zezjAC4A+Mi2zmaAE4Nz8iD3bDvrYf/Ra7yOd1bjPvtCpMf60QPh8WttXludpBgDAOp1PreceNUAUCF/e2eF5/k3iRcNAN0urwPQWef7E8xIjXM6EihKfo+IVU7XPcv4dc4jPnme85zznOTSA0BJjl8xPnZlLVw/wSzss0fF7u4PBkLvj40VQuwftF1WiESQ2IVIBIldiESQ2IVIBIldiEQYcsvmKo5MzwTjN67doON7Y+FUz7K3GDk7b6Fbtrh99kYrvNV3IpLCWozxnYN5ydNQxzJ+/NatcOrvkWmekFir8nLO1So/t2Wx1sSknHPE/opZlnnBrbkKaWXNUm8BIKsONrdY+m2vG7aRe5HS5DlZ02q1svMUVyHEHwYSuxCJILELkQgSuxCJILELkQgSuxCJILELkQhD9dnLssRaqxWMF5Gkx/HmoWAsb/O2yEWH++j1asSHL/JgrBXxRQ9MH6fxWjO89wAAWou8NsjsVNjHn2g26di8x1M1WWthAOhEUmAz4sOzsuIbd+BzKyKlqOHhc8fSa7NYKejIEZjHDwBFEV63Wo3Lcr0Tfr55Gc4L1pVdiESQ2IVIBIldiESQ2IVIBIldiESQ2IVIBIldiEQYbj57tYKZmbCnPBkpv3vjVtgrty730Q9NH+STc55zXpRhz3fpFm973I6Uc+6s83z2Shn2+AGgMhnef4BIOebxiA9vkToA1xd5S68OyTmvxHLpy/CeDACYHOdPX7ZqMY+/Gtlf0OvxtsqZRXx4sv+gF9k/ULBceZJoryu7EIkgsQuRCBK7EIkgsQuRCBK7EIkgsQuRCBK7EIkwVJ+90+3h/MWLwfjhQ8QvBuCVcA3zXiRBuRfJu66P8dbFK0vhls6x1sG9PObJ8iOMN8dovNEIxysV7mXHErvzgs/9YJM/ha7eCnvG2cS76Nj2zV/Q+PQB7oXfWg7vX6jX+bzL2IMaI7KuFVI/YW2d7y/IKuHHu15vBB/w6JXdzB4zs2tm9uKm2x4xs0tm9lz/6/7YcYQQo2U7b+O/AeC+LW7/srvf3f96cnenJYTYbaJid/dnACwMYS5CiD1kkA/oPmVmz/ff5gcbipnZGTObN7P51VW+j1oIsXfsVOxfBfBOAHcDuAzgi6E7uvtZdz/t7qcnJ3myiRBi79iR2N39qrsX7l4C+BqAe3Z3WkKI3WZHYjezY5t+/TCAF0P3FULsD6I+u5l9G8C9AA6b2UUAXwBwr5ndjQ038TyAT2znZFm1iubMkWB8aYl/DpjZOJknP3e9zn306YO8j/nSQrgufS/Si7sSi2d88kXkNdlInJQRBwDU6jvvrw4ARc5ru5uHx7eWLtCxsxN8XdY7fG4sJT3L+Lq02us0HllW1Cv8DiWpGz85Fn6eA0AF4bm11sIfjEXF7u4PbnHz12PjhBD7C22XFSIRJHYhEkFiFyIRJHYhEkFiFyIRhpri6nmOztLNYPwwKTMNAAsL4ZLMjUiL3OXIVt0bS7zcs3nYYqpnPI10epKnqEa6A6OMvCYXxAeKWWt5xDqr1vjfFrOgpsbDxy99kY6t17gFFU8dDk/OIqWeEYl3e9wWnGrydXMivR5pyQwAzWZ4XcoyXHdcV3YhEkFiFyIRJHYhEkFiFyIRJHYhEkFiFyIRJHYhEmGoPnulkuHQVLhazcT4BB3fPB5uL9xq8/K711a5J1tt8nOPHTgePve1V+jYei1cAhsA8kiL3sz5a/IYSYnMMj62jLQuLmPpuZHWxo0G+9sjecmRc1dJOWYAKEjP5s46fz6srXOvu9LgZc9vrfI23mzmvcjeh6kJnq4dQld2IRJBYhciESR2IRJBYhciESR2IRJBYhciESR2IRJhqD57XjoW2uESunlxg46fmjoQjJVlpKRxj/vwqIc9fADotMOlpIsK73RTi+SEW+QlN+bTs+NbpEx1WXAvuygi6xo5vll47nlOjHAAHnlM3fm5V9fDJZcLZsIDyCJFBsoOfz6tR+ZeRThemZijY7OM1WYIb07QlV2IRJDYhUgEiV2IRJDYhUgEiV2IRJDYhUgEiV2IRBiqz25ZBfWxsJ+9vBz2sgHg6NxtwdjiAm/33InkhI9H6s7TOuO9NTq2LLmH32jwuvIxnz4jOeWxfPZIGJVIzrhHcs6ZT2+RPttFJNc+j+wBGGuEj7/Q4ms+1eB/10qXn7s2xusjdNbCz/X66iU6tj0WnrtZFnzAold2M7vdzH5sZi+b2Utm9un+7TNm9pSZvdr/zhucCyFGynbexucAPuvudwH4CwCfNLO7AHwOwNPufieAp/u/CyH2KVGxu/tld/95/+cVAK8AOAHgAQCP9+/2OIAP7dUkhRCD83t9QGdmpwC8B8BPAcy5++V+6AqALTf0mtkZM5s3s/nVFd5PTQixd2xb7GY2CeB7AD7j7r+lWt/4lGbLTzTc/ay7n3b305MkkUUIsbdsS+xmVsOG0L/l7t/v33zVzI7148cAXNubKQohdoOo9WYb/sjXAbzi7l/aFHoCwEMAHu1//2H0bF6i7IVL+HqVW0znzv86GMs7bTq2MXGYxjtL12mcZVOeuo2nJEaaAyOLpIlmYTcFAGAkR9Yj5Zo9Mjt27A0i/abZ6SO2XdQ2jKSpohJOr630uFXbi6yLl/y52u3yFNgs3FkZ67TQNJARDWVZFtT0dnz29wL4GIAXzOy5/m0PY0Pk3zWzjwO4AOAj2ziWEGJERMXu7j9B+PX5/bs7HSHEXqHtskIkgsQuRCJI7EIkgsQuRCJI7EIkwlBTXFEUKFfC/mZecm9zbOZYMDbzjvfQscvnfkrjnoXbHgNAczzcJrdW4y1062M8Xq3sPIUVAEBSRWNppIMS8+Gr5CnmBffoY3sA2N+9cYDw+Gqdr2l7ne/bsAZ/TLOc++yzh2eCsbU2Pzfbu1CUYQNfV3YhEkFiFyIRJHYhEkFiFyIRJHYhEkFiFyIRJHYhEmGoPnutXsPxkyeD8QtvXA7GAF5yeXX5Fh37rjvvovGlW7yMdY144aR670bcdu6Tb4QjfjILD+BFA0AZiSPS2thJOehqjT/9yk6kXXTE4y/zTjgWa1UdaQeNPJxTDgCNyB6BKzfC7clPnjxBx968Ht6rUq2Gi0Loyi5EIkjsQiSCxC5EIkjsQiSCxC5EIkjsQiSCxC5EIgzVZ+92u7hw8Xww7o0pfgASn1y7Sof2xnmT2UYkP5nlrJNS3QDifnC0Lnyk9juD+dy7QRHxq1lN/LLkPnqsXXS3y73uXh4+fr0erikPAHlk3cpYu+mxWRqvTYafT1eu8z0jDVJP30kPbV3ZhUgEiV2IRJDYhUgEiV2IRJDYhUgEiV2IRJDYhUiE7fRnvx3ANwHMYaPV+Fl3/4qZPQLgbwG82dj8YXd/kh3LDehlYV/2XX9+L53Lr5/972Ds1B/9MR179TLPlZ88cJDGWUn7SsxHj/U4j+VOx1LS2eQifrBH8tGLSG33Mubjs6nxkdH9B5VIPf1GPexlxzx6i1wHKxW+L6MSWbfO+mIwVo3kws/MhmvO93q9YNH57WyqyQF81t1/bmZTAH5mZk/1Y19293/exjGEECNmO/3ZLwO43P95xcxeAcBLaQgh9h2/1//sZnYKwHsAvNlL6VNm9ryZPWZmW+5HNbMzZjZvZvOrq2sDTVYIsXO2LXYzmwTwPQCfcfdlAF8F8E4Ad2Pjyv/Frca5+1l3P+3upycnJ3ZhykKInbAtsZtZDRtC/5a7fx8A3P2quxe+8QnP1wDcs3fTFEIMSlTstlHa9OsAXnH3L226fXNL1Q8DeHH3pyeE2C2282n8ewF8DMALZvZc/7aHATxoZndjw1w5D+ATsQMZjJZkvnXlVTq+ceBAMPbSa+f4WOdtkU+cDB8bAFqt9WCsQlIOASCLxGPE7C/mrhVFsINvdCwAkAzV/h14mK1NtMp1pIV3LC2ZWXNjpAU3AHS7fN08MvlGlT9ms1PhdG2rcFnmvfCxM+JXbufT+J9ga0uUeupCiP2FdtAJkQgSuxCJILELkQgSuxCJILELkQgSuxCJMNRS0pZlaDQng/H1RZ6GWhZhb3PiIC8VPX343TR+8eILND47ezQ8r0iaZ0bSegHAomY2J8+JJxw5dEHKLQMbjxkjtseArU0sRTWr8GPHWlmz4xdFj46dmztM40XB163X5cdnnbCLXqzENimD7aZS0kKkjsQuRCJI7EIkgsQuRCJI7EIkgsQuRCJI7EIkgpEOr7t/MrPrAC5suukwgBtDm8Dvx36d236dF6C57ZTdnNvb3f3IVoGhiv13Tm427+6nRzYBwn6d236dF6C57ZRhzU1v44VIBIldiEQYtdjPjvj8jP06t/06L0Bz2ylDmdtI/2cXQgyPUV/ZhRBDQmIXIhFGInYzu8/M/sfMzpnZ50YxhxBmdt7MXjCz58xsfsRzeczMrpnZi5tumzGzp8zs1f53nsg/3Lk9YmaX+mv3nJndP6K53W5mPzazl83sJTP7dP/2ka4dmddQ1m3o/7ObWQXArwD8NYCLAJ4F8KC7vzzUiQQws/MATrv7yDdgmNlfAlgF8E13/5P+bf8EYMHdH+2/UE67+z/sk7k9AmB11G28+92Kjm1uMw7gQwD+BiNcOzKvj2AI6zaKK/s9AM65+2vu3gXwHQAPjGAe+x53fwbAwltufgDA4/2fH8fGk2XoBOa2L3D3y+7+8/7PKwDebDM+0rUj8xoKoxD7CQCvb/r9IvZXv3cH8CMz+5mZnRn1ZLZgzt3frN91BcDcKCezBdE23sPkLW3G983a7aT9+aDoA7rf5X3u/mcAPgjgk/23q/sS3/gfbD95p9tq4z0stmgz/htGuXY7bX8+KKMQ+yUAt2/6/WT/tn2Bu1/qf78G4AfYf62or77ZQbf//dqI5/Mb9lMb763ajGMfrN0o25+PQuzPArjTzO4wszqAjwJ4YgTz+B3MbKL/wQnMbALAB7D/WlE/AeCh/s8PAfjhCOfyW+yXNt6hNuMY8dqNvP25uw/9C8D92PhE/n8BfH4UcwjM6x0AftH/emnUcwPwbWy8reth47ONjwOYBfA0gFcB/BeAmX00t38D8AKA57EhrGMjmtv7sPEW/XkAz/W/7h/12pF5DWXdtF1WiETQB3RCJILELkQiSOxCJILELkQiSOxCJILELkQiSOxCJML/Azvo9FGDHSShAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVQPO2AJdz53"
      },
      "source": [
        "## Exploring Basic Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0relFMs2vC9K"
      },
      "source": [
        "tb_callbacks = keras.callbacks.TensorBoard(log_dir='./logs')\n",
        "\n",
        "model = Sequential() # 1\n",
        "\n",
        "# Preprocessing Layer\n",
        "model.add(keras.layers.experimental.preprocessing.RandomContrast(0.5)) \n",
        "model.add(keras.layers.experimental.preprocessing.RandomFlip(mode = \"horizontal_and_vertical\"))\n",
        "model.add(keras.layers.experimental.preprocessing.RandomRotation(factor=(-0.2, 0.3)))\n",
        "\n",
        "#Input layers\n",
        "model.add(Conv2D(32, kernel_size =(3,3), input_shape = (28,28,4), padding = \"same\", activation = 'relu', data_format='channels_last'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2), data_format= 'channels_last'))\n",
        "\n",
        "#Hidden layers\n",
        "model.add(Conv2D(64, kernel_size =(3,3), padding = \"same\", activation = 'relu', data_format='channels_last'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2), data_format= 'channels_last'))\n",
        "model.add(Dropout(0.7))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size =(3,3), padding = \"same\", activation = 'relu', data_format='channels_last'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2), data_format= 'channels_last'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#Final fully connected layer\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation = 'relu', input_shape = (28,28,4)))\n",
        "\n",
        "#Output layer\n",
        "model.add(Dense(4, activation = 'softmax'))\n",
        "\n",
        "model.compile(optimizer = 'SGD',\n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy']\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuoTiDr0mShs",
        "outputId": "91e6c68b-31be-41d9-f2a5-5e6d22e32825"
      },
      "source": [
        "model.fit(\n",
        "    X_train, \n",
        "    y_train, \n",
        "    batch_size = 64, \n",
        "    verbose=1, \n",
        "    validation_data=(X_test, y_test), \n",
        "    epochs=10, \n",
        "    callbacks=[tb_callbacks]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "5000/5000 [==============================] - 37s 7ms/step - loss: 0.1070 - accuracy: 0.9641 - val_loss: 0.1018 - val_accuracy: 0.9644\n",
            "Epoch 2/10\n",
            "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0931 - accuracy: 0.9690 - val_loss: 0.1926 - val_accuracy: 0.9400\n",
            "Epoch 3/10\n",
            "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0756 - accuracy: 0.9743 - val_loss: 0.0835 - val_accuracy: 0.9705\n",
            "Epoch 4/10\n",
            "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0684 - accuracy: 0.9774 - val_loss: 0.0629 - val_accuracy: 0.9797\n",
            "Epoch 5/10\n",
            "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0631 - accuracy: 0.9790 - val_loss: 0.0670 - val_accuracy: 0.9781\n",
            "Epoch 6/10\n",
            "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0597 - accuracy: 0.9804 - val_loss: 0.0558 - val_accuracy: 0.9812\n",
            "Epoch 7/10\n",
            "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0559 - accuracy: 0.9816 - val_loss: 0.0643 - val_accuracy: 0.9782\n",
            "Epoch 8/10\n",
            "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0538 - accuracy: 0.9824 - val_loss: 0.0517 - val_accuracy: 0.9842\n",
            "Epoch 9/10\n",
            "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0510 - accuracy: 0.9836 - val_loss: 0.0597 - val_accuracy: 0.9792\n",
            "Epoch 10/10\n",
            "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0493 - accuracy: 0.9840 - val_loss: 0.0544 - val_accuracy: 0.9835\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f04b96c7190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2ZGCpwHYV5p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4dd0906-8556-4ea4-b2c8-cbf362affb9f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "random_flip (RandomFlip)     (None, 28, 28, 4)         0         \n",
            "_________________________________________________________________\n",
            "random_rotation (RandomRotat (None, 28, 28, 4)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        1184      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               147584    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 241,636\n",
            "Trainable params: 241,636\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hzQM4K1b0lH"
      },
      "source": [
        "## Better CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U_4VuuTTfDa"
      },
      "source": [
        "tb_callbacks = keras.callbacks.TensorBoard(log_dir='./logs')\n",
        "\n",
        "model2 = Sequential() # 2\n",
        "\n",
        "# Preprocessing Layer\n",
        "model2.add(keras.layers.experimental.preprocessing.RandomContrast(0.5)) \n",
        "model2.add(keras.layers.experimental.preprocessing.RandomFlip(mode = \"horizontal_and_vertical\"))\n",
        "model2.add(keras.layers.experimental.preprocessing.RandomRotation(factor=(-0.2, 0.3)))\n",
        "\n",
        "#Input layers\n",
        "model2.add(Conv2D(32, kernel_size =(3,3), input_shape = (28,28,4), padding = \"same\", activation = 'relu', data_format='channels_last'))\n",
        "model2.add(MaxPooling2D(pool_size = (2,2), data_format= 'channels_last'))\n",
        "\n",
        "#Hidden layers\n",
        "model2.add(Conv2D(64, kernel_size =(3,3), padding = \"same\", activation = 'relu', data_format='channels_last'))\n",
        "model2.add(Conv2D(64, kernel_size =(3,3), padding = \"same\", activation = 'relu', data_format='channels_last'))\n",
        "model2.add(Conv2D(64, kernel_size =(3,3), padding = \"same\", activation = 'relu', data_format='channels_last'))\n",
        "model2.add(MaxPooling2D(pool_size = (2,2), data_format= 'channels_last'))\n",
        "model2.add(Dropout(0.7))\n",
        "\n",
        "model2.add(Conv2D(128, kernel_size =(3,3), padding = \"same\", activation = 'relu', data_format='channels_last'))\n",
        "model2.add(Conv2D(128, kernel_size =(3,3), padding = \"same\", activation = 'relu', data_format='channels_last'))\n",
        "model2.add(Conv2D(128, kernel_size =(3,3), padding = \"same\", activation = 'relu', data_format='channels_last'))\n",
        "model2.add(MaxPooling2D(pool_size = (2,2), data_format= 'channels_last'))\n",
        "model2.add(Dropout(0.7))\n",
        "\n",
        "#Final fully connected layer\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(128, activation = 'relu', input_shape = (28,28,4)))\n",
        "\n",
        "#Output layer\n",
        "model2.add(Dense(4, activation = 'softmax'))\n",
        "\n",
        "model2.compile(optimizer = 'SGD',\n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy']\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_Um0Sd-an1G",
        "outputId": "9c7782d4-d7c0-423e-95dc-0ec422e2b486"
      },
      "source": [
        "model2.fit(\n",
        "    X_train, \n",
        "    y_train, \n",
        "    batch_size = 512, \n",
        "    verbose=1, \n",
        "    validation_data=(X_test, y_test), \n",
        "    epochs=10, \n",
        "    callbacks=[tb_callbacks]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 38s 59ms/step - loss: 1.2886 - accuracy: 0.3847 - val_loss: 1.1542 - val_accuracy: 0.4897\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 0.9947 - accuracy: 0.5429 - val_loss: 0.9914 - val_accuracy: 0.5569\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 0.7762 - accuracy: 0.6752 - val_loss: 0.6403 - val_accuracy: 0.7269\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 0.5926 - accuracy: 0.7704 - val_loss: 0.4461 - val_accuracy: 0.8411\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 0.4517 - accuracy: 0.8395 - val_loss: 0.2900 - val_accuracy: 0.9063\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 0.3511 - accuracy: 0.8797 - val_loss: 0.4340 - val_accuracy: 0.8365\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 0.2819 - accuracy: 0.9036 - val_loss: 0.1711 - val_accuracy: 0.9419\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 0.2478 - accuracy: 0.9148 - val_loss: 0.2227 - val_accuracy: 0.9221\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 0.2133 - accuracy: 0.9280 - val_loss: 0.1420 - val_accuracy: 0.9502\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 0.2009 - accuracy: 0.9320 - val_loss: 0.1013 - val_accuracy: 0.9665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f049df6ce90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSDSL9zyTfDd",
        "outputId": "c43f06dc-dce5-4181-b3e5-8543301d7c02"
      },
      "source": [
        "print(\"Model 2 Summary\")\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 2 Summary\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "random_contrast_2 (RandomCon (None, 28, 28, 4)         0         \n",
            "_________________________________________________________________\n",
            "random_flip_3 (RandomFlip)   (None, 28, 28, 4)         0         \n",
            "_________________________________________________________________\n",
            "random_rotation_3 (RandomRot (None, 28, 28, 4)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 28, 28, 32)        1184      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 7, 7, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 7, 7, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               147584    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 4)                 516       \n",
            "=================================================================\n",
            "Total params: 610,660\n",
            "Trainable params: 610,660\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVvMVIaFbGC0"
      },
      "source": [
        "## Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePZahtTWbGC1"
      },
      "source": [
        "def build_model(hp):\n",
        "  model = Sequential() # 4\n",
        "  #model.add(keras.layers.experimental.preprocessing.RandomContrast(0.5)) \n",
        "  #model.add(keras.layers.experimental.preprocessing.RandomFlip(mode = \"horizontal_and_vertical\"))\n",
        "  #model.add(keras.layers.experimental.preprocessing.RandomRotation(factor=(-0.2, 0.3)))\n",
        "\n",
        "  model.add(Conv2D(hp.Int('input_units',min_value = 32, max_value = 224, step = 64), kernel_size =(3,3), input_shape = (28,28,4), padding = \"same\", activation = 'relu', data_format='channels_last'))\n",
        "  model.add(MaxPooling2D(pool_size = (2,2), data_format= 'channels_last'))\n",
        "\n",
        "  for i in range(hp.Int(\"n_layers\",1,3)):\n",
        "    model.add(Conv2D(hp.Int(f\"conv_{i}_units\",min_value = 32, max_value = 224, step = 64), kernel_size =(3,3), padding = \"same\", activation = 'relu', data_format='channels_last'))\n",
        "    # model.add(MaxPooling2D(pool_size = (2,2), data_format= 'channels_last'))\n",
        "    model.add(Dropout(0.7))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation = 'relu', input_shape = (28,28,4)))\n",
        "  model.add(Dense(4, activation = 'softmax'))\n",
        "\n",
        "  model.compile(optimizer = 'SGD',loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT6IrTfmbGC2"
      },
      "source": [
        "import time\n",
        "LOG_DIR = f\"{int(time.time())}\"\n",
        "\n",
        "tuner = Hyperband(\n",
        "    build_model,\n",
        "    objective = 'val_accuracy',\n",
        "    max_epochs = 1000,\n",
        "    executions_per_trial = 1,\n",
        "    directory = LOG_DIR,\n",
        "    project_name = 'layer_filter_variation3',\n",
        "    logger = TensorBoardLogger(metrics = [\"val_acc\"], logdir = './logs')\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "opy02Q43bGC3",
        "outputId": "4f845186-cb95-4961-ae89-c4d21d519a89"
      },
      "source": [
        "tuner.search(\n",
        "    x = X_train,\n",
        "    y = y_train,\n",
        "    verbose = 1,\n",
        "    epochs = 3,\n",
        "    batch_size = 512,\n",
        "    validation_data = (X_test,y_test)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 437 Complete [00h 00m 46s]\n",
            "val_accuracy: 0.8731625080108643\n",
            "\n",
            "Best val_accuracy So Far: 0.9118750095367432\n",
            "Total elapsed time: 05h 07m 08s\n",
            "\n",
            "Search: Running Trial #438\n",
            "\n",
            "Hyperparameter    |Value             |Best Value So Far \n",
            "input_units       |96                |96                \n",
            "n_layers          |2                 |1                 \n",
            "conv_0_units      |32                |160               \n",
            "conv_1_units      |160               |224               \n",
            "conv_2_units      |32                |96                \n",
            "tuner/epochs      |2                 |2                 \n",
            "tuner/initial_e...|0                 |0                 \n",
            "tuner/bracket     |6                 |6                 \n",
            "tuner/round       |0                 |0                 \n",
            "\n",
            "Epoch 1/2\n",
            "454/625 [====================>.........] - ETA: 3s - loss: 1.2101 - accuracy: 0.4271"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-48170d902e71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kerastuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kerastuner/tuners/hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tuner/epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'initial_epoch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tuner/initial_epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHyperband\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kerastuner/engine/multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'callbacks'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kerastuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, fit_args, fit_kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \"\"\"\n\u001b[1;32m    140\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZQ6GLI_bIyz"
      },
      "source": [
        "## Best Fit model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBiXLHwiYjyp"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWWptXK4Tqg4"
      },
      "source": [
        "tb_callbacks = keras.callbacks.TensorBoard(log_dir='./logs')\n",
        "\n",
        "model3 = Sequential()\n",
        "# Preprocessing Layer\n",
        "model3.add(keras.layers.experimental.preprocessing.RandomContrast(0.5)) \n",
        "model3.add(keras.layers.experimental.preprocessing.RandomFlip(mode = \"horizontal_and_vertical\"))\n",
        "model3.add(keras.layers.experimental.preprocessing.RandomRotation(factor=(-0.2, 0.3)))\n",
        "#Input layers\n",
        "model3.add(Conv2D(96, kernel_size =(3,3), input_shape = (28,28,4), padding = \"same\", activation = 'relu', data_format='channels_last'))\n",
        "model3.add(MaxPooling2D(pool_size = (2,2), data_format= 'channels_last'))\n",
        "\n",
        "#Hidden layers 1\n",
        "model3.add(Conv2D(160, kernel_size =(3,3), padding = \"same\", activation = 'relu', data_format='channels_last'))\n",
        "model3.add(Conv2D(224, kernel_size =(3,3), padding = \"same\", activation = 'relu', data_format='channels_last'))\n",
        "model3.add(Conv2D(96, kernel_size =(3,3), padding = \"same\", activation = 'relu', data_format='channels_last'))\n",
        "model3.add(MaxPooling2D(pool_size = (2,2), data_format= 'channels_last'))\n",
        "model3.add(Dropout(0.7))\n",
        "#Final fully connected layer\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(128, activation = 'relu', input_shape = (28,28,4)))\n",
        "#Output layer\n",
        "model3.add(Dense(4, activation = 'softmax'))\n",
        "#compiler\n",
        "model3.compile(optimizer = 'SGD',\n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy']\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMXTXUPwairy",
        "outputId": "c64548f3-ee75-43e4-9d59-29ec103b1c1e"
      },
      "source": [
        "model3.fit(\n",
        "    X_train, \n",
        "    y_train, \n",
        "    batch_size = 64, \n",
        "    verbose=1, \n",
        "    validation_data=(X_test, y_test), \n",
        "    epochs=10, \n",
        "    callbacks=[tb_callbacks]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "5000/5000 [==============================] - 51s 10ms/step - loss: 0.7425 - accuracy: 0.6838 - val_loss: 0.3297 - val_accuracy: 0.8801\n",
            "Epoch 2/10\n",
            "5000/5000 [==============================] - 49s 10ms/step - loss: 0.2106 - accuracy: 0.9254 - val_loss: 0.0966 - val_accuracy: 0.9689\n",
            "Epoch 3/10\n",
            "5000/5000 [==============================] - 49s 10ms/step - loss: 0.1351 - accuracy: 0.9542 - val_loss: 0.1005 - val_accuracy: 0.9644\n",
            "Epoch 4/10\n",
            "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0995 - accuracy: 0.9665 - val_loss: 0.0558 - val_accuracy: 0.9811\n",
            "Epoch 5/10\n",
            "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0839 - accuracy: 0.9719 - val_loss: 0.0590 - val_accuracy: 0.9804\n",
            "Epoch 6/10\n",
            "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0687 - accuracy: 0.9767 - val_loss: 0.0398 - val_accuracy: 0.9870\n",
            "Epoch 7/10\n",
            "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0604 - accuracy: 0.9800 - val_loss: 0.0411 - val_accuracy: 0.9867\n",
            "Epoch 8/10\n",
            "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0551 - accuracy: 0.9818 - val_loss: 0.0397 - val_accuracy: 0.9874\n",
            "Epoch 9/10\n",
            "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0480 - accuracy: 0.9842 - val_loss: 0.0410 - val_accuracy: 0.9863\n",
            "Epoch 10/10\n",
            "5000/5000 [==============================] - 49s 10ms/step - loss: 0.0449 - accuracy: 0.9849 - val_loss: 0.0331 - val_accuracy: 0.9890\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f04b85ad150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WemARa-aObYf",
        "outputId": "67e7edb6-0318-45dc-b75c-4c2bc07d6211"
      },
      "source": [
        "print(\"Model 3 Summary\")\n",
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 3 Summary\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "random_contrast_6 (RandomCon (64, 28, 28, 4)           0         \n",
            "_________________________________________________________________\n",
            "random_flip_7 (RandomFlip)   (64, 28, 28, 4)           0         \n",
            "_________________________________________________________________\n",
            "random_rotation_7 (RandomRot (64, 28, 28, 4)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (64, 28, 28, 96)          3552      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (64, 14, 14, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (64, 14, 14, 160)         138400    \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (64, 14, 14, 224)         322784    \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (64, 14, 14, 96)          193632    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (64, 7, 7, 96)            0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (64, 7, 7, 96)            0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (64, 4704)                0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (64, 128)                 602240    \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (64, 4)                   516       \n",
            "=================================================================\n",
            "Total params: 1,261,124\n",
            "Trainable params: 1,261,124\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkfVHASbq5GC"
      },
      "source": [
        "### File mangement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc8T2FLSq953"
      },
      "source": [
        "!cp \"/content/basic1 Batch 256 logs\" -r \"/content/drive/MyDrive/Colab Notebooks\"\n",
        "!cp \"/content/basic1 Batch 64 logs\" -r \"/content/drive/MyDrive/Colab Notebooks\"\n",
        "!cp \"/content/finetuned3 Batch 512 logs\" -r \"/content/drive/MyDrive/Colab Notebooks\"\n",
        "!cp \"/content/finetuned3 Batch 64 logs\" -r \"/content/drive/MyDrive/Colab Notebooks\"\n",
        "!cp \"/content/logs\" -r \"/content/drive/MyDrive/Colab Notebooks\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5unJml2FrhBg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}